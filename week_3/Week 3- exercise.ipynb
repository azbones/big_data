{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3 Exercise\n",
    "\n",
    "**Assignment**: This exercise will use Google BigQuery to explore the GSOD weather dataset.  Specifically, you will:\n",
    "  \n",
    "* Use the <code>read_gbq</code> to retrieve data from the GSOD dataset\n",
    "* Use pandas to describe the data\n",
    "* Use SQL-like syntax to return summarized data to pandas from BigQuery\n",
    "* Use <code>pivot_table</code> to display the data by month and year\n",
    "* Compare and contrast PaaS versus build-it-yourself analytics solutions\n",
    "* Discuss approaches to optimizing aggregation performance in a PaaS workflow\n",
    "\n",
    "For this exercise, you will have to complete all the tasks within this notebook, save the entire notebook, and then upload into the Week 3 Assignment for your group on BlackBoard. Save this notebook with a new name with the following format:\n",
    "\n",
    "**Week_3_Exercise_Group_group_number.ipynb**\n",
    "\n",
    "These in-class exercises are designed to allow you to explore Python with your group and **DO NOT** include step-by-step directions or answers that have only one possibility. Use your team and other resources to determine how best to complete them. Make sure before you turn in your notebook that it runs without errors and the requested output is visible in the notebook. If you go through multiple steps in your code, make sure all those steps are included so that we can evaluate your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to begin by exploring the GSOD dataset. Additional details about it can be found here:\n",
    "\n",
    "* http://www1.ncdc.noaa.gov/pub/data/gsod/readme.txt\n",
    "\n",
    "To begin, use the <code>read_gbq</code> function to retrieve the temperatures and dew points for the years 2013 and 2014 for days when there was hail from the <code>fh-bigquery:weather_gsod</code> dataset in BigQuery. Complete the other tasks in the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from the criteria above and print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the average temperature of that dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the average dewpoint of that dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the number of observations in this dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the number of unique stations (hint: try value_counts) these observations represent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the mean, max, and min temperatures and dew points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, retrieve temperature and pressure observations in the dataset <code>fh-bigquery:weather_gsod</code> from 2013 that had hail or funnel clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from BigQuery and the criteria above and print it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the number of observations in the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print some descriptive statistics for the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the mean temperature on days it hailed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the mean temperature on days when a tornado or funnel cloud was observed\n",
    "# Remember http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the number of stations that observed a tornado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use BigQuery to return the average temperatures by month and year for the larger <code>publicdata:samples.gsod</code> dataset to a new dataframe. Make sure the returned data is ordered by year and month in ascending order. Hint: groupby\n",
    "\n",
    "The format should be similar to:\n",
    "\n",
    "```\n",
    "YEAR|MONTH|AVERAGE_TEMP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new dataframe with average temps by year and month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use <code>pivot_table</code> to create a new dataframe that has years as the rows and months as the columns with the average temperatures as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new dataframe years as rows and months as columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, I have created a function called <code>box_plot</code> which will take a properly formatted dataframe and create an inline boxplot. Run the code in the follow block to read it into the namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "import calendar\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = 16, 10  #default image size for this interactive session\n",
    "\n",
    "def box_plot(weather):\n",
    "    \"\"\"\n",
    "    Take a dataframe of years in rows, months in columns, temps in values and return a boxplot.\n",
    "    \"\"\"\n",
    "    weather.dropna(inplace=True)\n",
    "    plt.figure('weather')\n",
    "    plt.boxplot(weather.values)\n",
    "    month_list=[calendar.month_abbr[i] for i in np.arange(1,13)]\n",
    "    plt.xticks(range(1,13),month_list, rotation=15)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel(u'Average Temperature in F\\u00b0')\n",
    "    plt.title('GSOD Temperatures by Month for All Years and All Stations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use <code>box_plot</code> to create the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use box_plot to plot your dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 1\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "What observations can you make about this dataset from the boxplot (you can use bullets in your response)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 2\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "* Discuss some examples of data you may have had experience with that was in a record format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 3\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "Some recent IT articles have suggested most firms deal with small or medium data rather than Internet-scale or \"big data\".\n",
    "\n",
    "* What upsides and downsides to you see for a firm that has medium or small data using technologies that were built for large scale applications at companies like Google and Amazon?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 4\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "What are the benefits and drawbacks of a \"big data\" technology strategy that:\n",
    "\n",
    "* uses a PaaS analytics provider like Google?\n",
    "* uses open-source software like Hadoop or Spark on the firm's server infrastructure? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 5\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "Given a data science workflow that uses Google BigQuery in the cloud and Python on the desktop, how would approach determining where to perform aggregate functions?  Specifically, when should you use SQL aggregate functions on BigQuery versus in memory pandas aggregate functions on your desktop?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
