{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Tuesday Exercise\n",
    "\n",
    "**Assignment**: This exercise will use pandas and TextBlob to explore tweet data.  Specifically, you will:\n",
    "  \n",
    "* Read a file of tweets into a dataframe\n",
    "* Use pandas to describe and analyze the data\n",
    "* Use TextBlob to further analyze the tweet contents and their sentiment\n",
    "* Discuss how these methods might be used by relevant firms\n",
    "* Explore an extension of tweet-specific sentiment analysis\n",
    "\n",
    "For this exercise, you will have to complete all the tasks within this notebook, save the entire notebook, and then upload into the Week 4 Tuesday Assignment for your group on BlackBoard. Save this notebook with a new name with the following format:\n",
    "\n",
    "**Week_4_Tues_Exercise_Group_group_number.ipynb**\n",
    "\n",
    "These in-class exercises are designed to allow you to explore Python with your group and **DO NOT** include step-by-step directions or answers that have only one possibility. Use your team and other resources to determine how best to complete them. Make sure before you turn in your notebook that it runs without errors and the requested output is visible in the notebook. If you go through multiple steps in your code, make sure all those steps are included so that we can evaluate your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, unzip and read the tweet data from the file from the datasets folder named 'pokemon.zip' into a dataframe and describe the dataset.\n",
    "\n",
    "**Analyze Tweet Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read file with tweet data into a dataframe and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many tweets are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many of the tweets are retweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many of the tweets are in English?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to unpack an individual element into its own column in a new dataframe or your existing dataframe, you can use this general approach:\n",
    "\n",
    "```\n",
    "dataframe['new column'] = dataframe['column to unpack'].map(lambda tweet: tweet['key to unpack'])\n",
    "```\n",
    "\n",
    "Ptyhon's <code>map</code> function applies a function to every element of an iterable.  Yes, this is similar to the big data concept of map-reduce which we will cover in more detail later. Python's <code>lambda</code> function is a way to make an anonymous one line function. Don't worry about the details of the syntax and instead focus on the functionality.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print a list the count of user entered locations by number of occurrences in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many tweets originated in the user defined location of Hyrule?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many distinct users tweeted from the user defined location of Hyrule?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look into the text of the tweets.  Specifically, use the the function in the next code block to retrieve the URLs in the tweet text and write them to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def find_url(text):\n",
    "    \"\"\"\n",
    "    Return first URL match from a string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url_re = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "        url = re.search(url_re, text)\n",
    "        if url:\n",
    "            return url.group()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new column in dataframe with URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of non-null URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the list of non-null URLs, create a list by number of occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Analysis of Tweets**\n",
    "\n",
    "Next, use the TextBlob library to further analyze the tweet data. If you wish to aggregate any individual elements into a single string object, you can use the following pattern.\n",
    "\n",
    "````\n",
    "str_object = ' '.join(iterable sequence)\n",
    "````\n",
    "\n",
    "This pattern concatenates a sequence together with a space between each element.\n",
    "\n",
    "Note that language tags use the following IETF format:\n",
    "\n",
    "* http://tools.ietf.org/html/bcp47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the count of tweets by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the most popular Pokémon character in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the most popular single emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the polarity and subjectivity of the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 1\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "* Using your measures of characters, emoji, polarity, and subjectivity, how would you describe the text in terms of interests and sentiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 2\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "* How do you think the Pokémon Company (which is owned by Ninetendo) uses streaming data like this?\n",
    "* What specific applications could it have for product development?\n",
    "* What other streaming datasets (internal or external) might the Pokémon Company use with the Twitter data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 3\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "* How might emoji be used in sentiment analysis?\n",
    "* How could TextBlob be used to create an emoji sentiment analysis?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
