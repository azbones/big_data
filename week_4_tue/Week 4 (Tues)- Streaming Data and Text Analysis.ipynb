{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 (Tuesday)- Streaming Data and Text Analysis\n",
    "\n",
    "**Objectives**: Today we are going to explore streaming data and text analysis. Specifically, we will cover the following:\n",
    "  \n",
    "* Streaming Data\n",
    "* Build code to connect to the Twitter streaming API\n",
    "* Experiment with that code to generate different streams\n",
    "* Use TextBlob to analyze results from API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Streaming Data\n",
    "\n",
    "Streaming data, especially like that from services like Twitter, embodies all three of the \"big data\" V's- variety, velocity, and volume. Much of this data is also unstructured. In this context, we are discussing streaming data and not streaming media like video or audio although streaming media is also a component of \"big data\".\n",
    "\n",
    "For analytics and streaming data, a typical use case might look like the following example from Amazon Web S\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/azbones/big_data/master/images/Kinesis-Streams_Diagram.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweet_stream import TwitterAuth, PrintStream, FileStream, get_stream\n",
    "\n",
    "# consumer_key = 'insert_here'\n",
    "# consumer_secret = 'insert_here'\n",
    "# access_token = 'insert_here'\n",
    "# access_token_secret = 'insert_here'\n",
    "\n",
    "consumer_key = 'insert_here'\n",
    "consumer_secret = 'insert_here'\n",
    "access_token = 'insert_here'\n",
    "access_token_secret = 'insert_here'\n",
    "\n",
    "auth = TwitterAuth(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "con = auth.make_connector()\n",
    "listener = PrintStream()\n",
    "stream = get_stream(con, listener)\n",
    "stream.filter(track=['Broncos','Cardinals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tweets = []\n",
    "f = open('tweets.txt', 'r')\n",
    "for line in f:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets.append(tweet)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tweets)\n",
    "\n",
    "test_me=df.ix[26]['retweeted_status']\n",
    "\n",
    "org_tweets=df[df['retweeted_status'].isnull()]\n",
    "\n",
    "df['text'].value_counts()\n",
    "org_tweets.ix[0:1000]['text']\n",
    "org_tweets_blob=''.join(org_tweets)\n",
    "org_list=org_tweets['text'][~org_tweets['text'].isnull()].tolist()\n",
    "org_list=org_tweets['text'].tolist()\n",
    "text_blob = ''.join(org_list)\n",
    "df['text'][1]\n",
    "text_blob[:3000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
