{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6- Machine Learning\n",
    "\n",
    "**Objectives**: Today we are going to work with some basic machine learning algorithms. Machine learning is a rich and exciting area of computer science that is often considered a subset of the broader field of artifical intellegence. At its most basic level, machine learning seeks to build algorithms that allow systems to perform actions without explicitly being programmed. Today we are going to: \n",
    "  \n",
    "* Review examples of machine learning\n",
    "* Supervised\n",
    "* Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Machine learning is a core component of many data-driven products. Recommendation engines, self-driving cars, credit scoring, spam filtering, product ranking, customer support, and even medical diagnoses are all examples of where machine learning is being applied. \n",
    "\n",
    "Machine learning is in the top five skills identified in LinkedIn profiles of current data scientists. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/azbones/big_data/master/images/rjmetrics-ml.png\">\n",
    "(source: https://rjmetrics.com/resources/reports/the-state-of-data-science/)\n",
    "\n",
    "\n",
    "There are now even dedicated machine learning firms like Dato seeking to deliver simple machine learning products at scale:\n",
    "\n",
    "* [Dato](https://dato.com/): \"Sophisticated Machine Learning Made Easy\"\n",
    "\n",
    "Amazon Web Services has a machine learning product which can be used for batch or real time analysis on their infrastructure.\n",
    "\n",
    "* [Amazon Web Services Machine Learning](https://aws.amazon.com/machine-learning/)\n",
    "\n",
    "Google recently open-sourced part of their machine learning libraries which are available at:\n",
    "\n",
    "* \"[Tensorflow](http://www.tensorflow.org/) is designed to facilitate research in machine learning, and to make it quick and easy to transition from research prototype to production system.\"\n",
    "\n",
    "Microsoft's Azure platform now has a machine learning product that is part of their Cortana Analytics Suite which has a drag and drop interface (ML Studio) for deploying machine learning in their cloud using R and Python.\n",
    "\n",
    "* [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/) is \"a fully managed big data and advanced analytics suite that enables you to transform your data into intelligent action.\"\n",
    "\n",
    "\n",
    "Even non-profits like Kahn Academy are using machine learning in their production systems:\n",
    "\n",
    "* [Khan Academy Machine Learning → Measurable Learning](http://derandomized.com/post/51729670543/khan-academy-machine-learning-measurable)\n",
    "\n",
    "If you are interested in learning more about Machine Learning, I suggest the course by Andrew Ng from Stanford which is available on Coursera:\n",
    "\n",
    "* https://www.coursera.org/learn/machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "One way to subdivide the machine learning domain is by supervised or unsupervised learning. \n",
    "\n",
    "In supervised learning, a training dataset is being to build a model which is then applied to new observations to make predictions. The training dataset has both the predictor variables (often called features in ML parlence) and the \"correct\" answers or outcome that you are seeking to predict. Often a seperate, test dataset is used to measure how well the model performs with new data.\n",
    "\n",
    "Predictions can include:\n",
    "\n",
    "* **Classification:** The model is used to classify observations into categorical values or classes (e.g.- for a cancer test, there might be the categories of \"benign\", \"precancerous\", and \"malignant\").\n",
    "\n",
    "* **Regression:** The model is used to predict values that are continuous in nature (e.g.- measures with infinite measures like temperature).\n",
    "\n",
    "Supervised machine learning algorithms can include:\n",
    "\n",
    "* Decision trees\n",
    "* Discriminant analysis\n",
    "* Naïve Bayes classifiers\n",
    "* Nearest neighbors\n",
    "* Neural networks\n",
    "* Support machine vectors\n",
    "\n",
    "Today, we are going to use the Nearest Neighbor or K-Nearest Neighbor (KNN) algorithm to explore supervised learning in a classification example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN Algorithm**\n",
    "\n",
    "KNN is one of the simplest and most used supervised learning algorithms. While it can be used for both regression and classification, we are going to use it for classification.\n",
    "\n",
    "Simply, the algorithm uses the distance between an observation and its feature vector (the value of the features that describe it) and the training dataset to determine group membership. \n",
    "\n",
    "The K refers to the number of neighbors you set to evaluate versus each observation. The algorithm uses distance (most often Euclidian although there are many options here) to determine the K closest neighbors and then classify the observation based on the class that results in the smallest misclassification cost. You should select odd values of K to avoid any ties when calculating the lowest misclassification cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Synthetic Dataset**\n",
    "\n",
    "To begin, we are going to create a synthetic dataset using the scikit-learn machine learning library. The <code>make_blobs</code> function allows us to create different distinct groups which populates group membership from a gaussian distribution.\n",
    "\n",
    "Our synthetic dataset will have 1000 samples, 5 defined centers, and 2 features.\n",
    "\n",
    "```\n",
    "X -upper case X- represents the matrix of feature values\n",
    "y -lower case y- represents the 1-dimensional vector of outcome categories\n",
    "```\n",
    "Run the code in the following block to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=1000, centers=5, n_features=2,\n",
    "                  random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore X and y to see the shape of the arrays and their values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, while we could work with the numpy arrays directly, we are going to read them into a pandas dataframe for convienence. Do that in the next codeblock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from numpy arrays\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=X, index=y, columns=['feature 1', 'feature 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the dataframe structure to the numpy array below. Where are X and y represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the Synthetic Data**\n",
    "\n",
    "Now, we are going to plot the features as x and y coordinates and the outcome groupings by color. Remember this data is our training dataset, so we have both the predictors (x and y) and the thing we want to predict, group membership. Practically, an example of this might be features of e-mail and whether we, as experts, classified those individual messages as spam or non-spam.\n",
    "\n",
    "Plot the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Plot data\n",
    "sns.set_style(\"darkgrid\")\n",
    "mpl.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "group1 = plt.scatter(df['feature 1'].ix[0], df['feature 2'].ix[0], c='b', label='group 1')\n",
    "group2 = plt.scatter(df['feature 1'].ix[1], df['feature 2'].ix[1], c='c', label='group 2')\n",
    "group3 = plt.scatter(df['feature 1'].ix[2], df['feature 2'].ix[2], c='r', label='group 3')\n",
    "group4 = plt.scatter(df['feature 1'].ix[3], df['feature 2'].ix[3], c='k', label='group 4')\n",
    "group5 = plt.scatter(df['feature 1'].ix[4], df['feature 2'].ix[4], c='w', label='group 5')\n",
    "legend = plt.legend(handles=[group1,group2,group3,group4,group5], frameon=1)\n",
    "legend.get_frame().set_facecolor('#ffffff')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the KNN Model**\n",
    "\n",
    "Next, we are going to build our KNN classifier and fit the model to the training data.  For this initial attempt, we will use a K value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "\n",
    "# Create KNN classifier and fit model\n",
    "X, y = df.values, df.index\n",
    "n_neighbors = 1\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict Group Membership for a New Observation**\n",
    "\n",
    "Now we have a classifier that can take any two feature inputs and predict group membership. Populate the features with some example values and run the prediction in the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict group membership based values entered in predict fucntion\n",
    "\n",
    "classes = ['Group 1','Group 2','Group 3','Group 4','Group 5']\n",
    "obs_one = 100\n",
    "obs_two = 250\n",
    "\n",
    "prediction = classes[knn.predict([[obs_one, obs_two]])[0]]\n",
    "\n",
    "print 'An observation with feature-one value of {} and feature-two value of '\\\n",
    "      '{} is a member of {}'.format(obs_one,obs_two,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the Feature Space for the Model**\n",
    "\n",
    "Because we only have two features in our test dataset, we can plot all predicted values on a two-dimensional plane to visualize how the algorithm is working. This is accomplished by building a meshgrid or array of every possible space in the plot and using the KNN classifier to predict group membership for all these values. Each group is assigned a distinct color.\n",
    "\n",
    "Run the code below to see the plot of all predictions within the space defined by the min and max for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import neighbors, datasets\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Set up colors for mesh\n",
    "mesh_cmap = ListedColormap(['#9E9AB2', '#FFBE8C', '#7F63FF', '#3CCC3B', '#83B283'])\n",
    "\n",
    "\n",
    "# Set up array for plotting predictions\n",
    "x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure('KNN Without Training Data')\n",
    "plt.title('KNN with {} Neighbors Without Training Data'.format(n_neighbors))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=mesh_cmap)\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.xlabel('X Values')\n",
    "plt.ylabel('Y values')\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Training Data and the Model Data**\n",
    "\n",
    "Now, plot the predicted value feature space and then plot the training data over the predictions with the next codeblock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure('KNN with Training Data')\n",
    "plt.title('KNN with {} Neighbors and Training Data'.format(n_neighbors))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=mesh_cmap)\n",
    "group1 = plt.scatter(df['feature 1'].ix[0], df['feature 2'].ix[0], c='b', label='group 1')\n",
    "group2 = plt.scatter(df['feature 1'].ix[1], df['feature 2'].ix[1], c='c', label='group 2')\n",
    "group3 = plt.scatter(df['feature 1'].ix[2], df['feature 2'].ix[2], c='r', label='group 3')\n",
    "group4 = plt.scatter(df['feature 1'].ix[3], df['feature 2'].ix[3], c='k', label='group 4')\n",
    "group5 = plt.scatter(df['feature 1'].ix[4], df['feature 2'].ix[4], c='w', label='group 5')\n",
    "legend = plt.legend(handles=[group1,group2,group3,group4,group5], frameon=1)\n",
    "legend.get_frame().set_facecolor('#ffffff')\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.xlabel('X Values')\n",
    "plt.ylabel('Y values')\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N-dimensional Features**\n",
    "\n",
    "While our example using two features was instructive as a visualization, most machine learning problems will have many more features. Unfortunately, plotting the feature space of predictions is not possible beyond three dimensions (even three dimensional plots are difficult to use given they are rendered in two dimensions). The KNN models work exactly the same way, regardless of the number of features.\n",
    "\n",
    "Build a synthetic dataset with three features below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2, y2 = make_blobs(n_samples=1000, centers=4, n_features=3,\n",
    "                  random_state=4)\n",
    "df2 = pd.DataFrame(data=X2, index=y2, columns=['feature 1', 'feature 2', 'feature 3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training values with a 3D projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sns.set_style(\"whitegrid\")\n",
    "mpl.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "fig = plt.figure('3D')\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "group1 = ax.scatter(df2['feature 1'].ix[0], df2['feature 2'].ix[0], df2['feature 3'].ix[0], c='b', label='group 1')\n",
    "group2 = ax.scatter(df2['feature 1'].ix[1], df2['feature 2'].ix[1], df2['feature 3'].ix[1], c='c', label='group 2')\n",
    "group3 = ax.scatter(df2['feature 1'].ix[2], df2['feature 2'].ix[2], df2['feature 3'].ix[2], c='r', label='group 3')\n",
    "group4 = ax.scatter(df2['feature 1'].ix[3], df2['feature 2'].ix[3], df2['feature 3'].ix[3], c='k', label='group 4')\n",
    "ax.set_xlabel('X Values')\n",
    "ax.set_ylabel('Y Values')\n",
    "ax.set_zlabel('Z Values')\n",
    "legend = plt.legend(handles=[group1,group2,group3,group4], frameon=1)\n",
    "legend.get_frame().set_facecolor('#ffffff')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the KNN Model for Three Features**\n",
    "\n",
    "Next, we are going to build our KNN classifier and fit the model to the new training data.  For this initial attempt, we will use a K value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes_3d = ['Group 1','Group 2','Group 3','Group 4']\n",
    "n_neighbors = 1\n",
    "knn_3d = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn_3d.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict Group Membership with Three Values**\n",
    "\n",
    "Populate the observation values and predict group membership below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs_3d_one = \n",
    "obs_3d_two = \n",
    "obs_3d_three = \n",
    "\n",
    "prediction_3d = classes_3d[knn_3d.predict([[obs_3d_one, obs_3d_two, obs_3d_three]])[0]]\n",
    "\n",
    "print 'An observation with a feature-one value of {}, a feature-two value of '\\\n",
    "      '{}, and a feature-three value of {} is a member of {}'.format(obs_3d_one,obs_3d_two,\n",
    "                                                                     obs_3d_three,prediction_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "\n",
    "One way to subdivide the machine learning domain is by supervised or unsupervised learning. \n",
    "\n",
    "As you may have guessed, unsupervised learning does not use a training set, but instead draws inferences about the data from the data itself without defined labels.\n",
    "\n",
    "The most common use case for unsupervised learning is cluster analysis. Examples of cluster analysis include:\n",
    "\n",
    "* **Genetic Classification:** Genone sequencing dataset can be used to group individuals or organisms with similar properties.\n",
    "\n",
    "* **Document Classification:** Documents with similar topics, based on NLP, can be grouped together. \n",
    "\n",
    "\n",
    "Unsupervised machine learning algorithms can include:\n",
    "\n",
    "* Gaussian mixture models\n",
    "* Hidden Markov models\n",
    "* Hierarchial clustering\n",
    "* k-Means clustering\n",
    "\n",
    "We are going to use the k-Means algorithm, again from the sci-kit learn package, to explore unsupervised learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
